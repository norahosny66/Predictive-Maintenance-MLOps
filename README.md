# Predictive Maintenance MLOps Pipeline

![Terraform](https://img.shields.io/badge/Provisioning-Terraform-623CE4?logo=terraform)
![Ansible](https://img.shields.io/badge/Configuration-Ansible-EE0000?logo=ansible)
![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Prefect](https://img.shields.io/badge/Orchestration-Prefect-ffb400.svg)
![MLflow](https://img.shields.io/badge/Experiment%20Tracking-MLflow-green.svg)
![CI/CD](https://img.shields.io/badge/CI/CD-Jenkins-orange.svg)
![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)

---

## Overview

This repository implements a **production-grade MLOps pipeline** for **predictive maintenance of rotating machinery (bearings)**, using the [NASA Bearing Dataset].
---

## Problem Statement

Industrial equipment failures, such as bearing breakdowns, lead to:
- Expensive **unplanned downtime**
- Higher **maintenance expenses**
- Significant **safety risks**

Traditional time-based maintenance schedules waste resources and fail to prevent unexpected failures.

**Goal:**  
Predict failures **before they happen** by:
1. Analyzing vibration and sensor time-series data.
2. Building ML models to predict Remaining Useful Life (RUL) or failure probability.
3. Detecting **data drift** and **performance degradation** automatically.
4. Triggering **retraining and alerts** when model reliability drops.

---
## ğŸ” Solution Architecture

```mermaid
graph TD
    A[NASA Bearing Dataset] --> B[Terraform AWS Provisioning]
    B --> C[EC2 + S3 + IAM Roles]
    C --> D[Ansible Configuration]
    D --> E[Custom Docker Images]
    E --> F[Prefect Orchestration]
    F --> G[MLflow Tracking]
    G --> H[FastAPI Serving]
    H --> I[Evidently AI Monitoring]
    I --> J{Drift Detected?}
    J -- Yes --> K[Teams Alert]
    J -- Yes --> L[Auto-Retrain]
    J -- No --> M[Continuous Monitoring]
    L --> F
```

---
ğŸ“‚ Repository Structure
```bash
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ Terraform
â”‚Â Â  â”œâ”€â”€ backends.tf
â”‚Â Â  â”œâ”€â”€ ec2.tf
â”‚Â Â  â”œâ”€â”€ iam.tf
â”‚Â Â  â”œâ”€â”€ main.tf
â”‚Â Â  â”œâ”€â”€ outputs.tf
â”‚Â Â  â”œâ”€â”€ providers.tf
â”‚Â Â  â”œâ”€â”€ s3.tf
â”‚Â Â  â”œâ”€â”€ state
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ terraform.tfstate
â”‚Â Â  â”‚Â Â  â””â”€â”€ terraform.tfstate.backup
â”‚Â Â  â””â”€â”€ variables.tf
â”œâ”€â”€ ansible
â”‚Â Â  â”œâ”€â”€ inventory
â”‚Â Â  â”‚Â Â  â””â”€â”€ hosts.ini
â”‚Â Â  â”œâ”€â”€ jenkins
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ docker-compose-jenkins.yml
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dockerpermissions.yml
â”‚Â Â  â”‚Â Â  â””â”€â”€ jenkins.yml
â”‚Â Â  â”œâ”€â”€ mlflow
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ docker-compose-mlflow.yml
â”‚Â Â  â”‚Â Â  â””â”€â”€ mlflow.yml
â”‚Â Â  â””â”€â”€ prefect
â”‚Â Â      â”œâ”€â”€ docker-compose-prefect.yml
â”‚Â Â      â”œâ”€â”€ prefect.yml
â”‚Â Â      â”œâ”€â”€ start-agent.sh
â”‚Â Â      â””â”€â”€ start-agent.sh:Zone.Identifier
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ drifted
â”‚Â Â  â”‚Â Â  â””â”€â”€ 1st_test
â”‚Â Â  â”œâ”€â”€ processed
â”‚Â Â  â”‚Â Â  â””â”€â”€ features.csv
â”‚Â Â  â””â”€â”€ raw
â”‚Â Â      â””â”€â”€ Nasa-Bearing
â”‚Â Â          â”œâ”€â”€ 1st_test
â”‚Â Â          â”œâ”€â”€ 2st_test
â”‚Â Â          â”œâ”€â”€ 3rd_test
â”‚Â Â          â””â”€â”€ Readme Document for IMS Bearing Data.pdf
â”œâ”€â”€ full_pipeline-deployment.yaml
â”œâ”€â”€ mlruns
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ .ipynb_checkpoints
â”‚Â Â  â”‚Â Â  â””â”€â”€ eda_features-checkpoint.ipynb
â”‚Â Â  â””â”€â”€ eda_features.ipynb
â”œâ”€â”€ prefect
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â”œâ”€â”€ docker-compose.yml
â”‚Â Â  â”œâ”€â”€ monitor_pipeline-deployment.yaml
â”‚Â Â  â””â”€â”€ start-agent.sh
â”œâ”€â”€ setup.py
â””â”€â”€ src
    â”œâ”€â”€ deployment-pipeline.py
    â”œâ”€â”€ extract_features.py
    â”œâ”€â”€ full_pipeline-deployment.yaml
    â”œâ”€â”€ monitoring
    â”‚Â Â  â”œâ”€â”€ alert.py
    â”‚Â Â  â”œâ”€â”€ drift_check.py
    â”‚Â Â  â”œâ”€â”€ prefect_monitor_flow.py
    â”‚Â Â  â”œâ”€â”€ simulate_drifting.py
    â”‚Â Â  â””â”€â”€ workflow_trigger.py
    â”œâ”€â”€ serving
    â”‚Â Â  â”œâ”€â”€ app.py
    â”‚Â Â  â””â”€â”€ input_example.json
    â””â”€â”€ train.py
```
## ğŸŒŸ Key Features

### ğŸš€ Infrastructure Automation
- **Terraform-provisioned EC2 on AWS** with Elastic IP  
- **S3 bucket** for data/model storage  
- **IAM roles** for secure S3 access  
- **Security groups** with least-privilege ports  

### ğŸ³ Custom Docker Images
- `prefect-agent-custom`: Pre-loaded with Python 3.10 + dependencies  
- `jenkins`: Handle permissions to use separate docker containers as agents for CI/CD pipelines  

### ğŸ” ML Lifecycle Management
- **workflow orchestration** using prefect
- **Model versioning** in MLflow Registry  
- **Automated retraining triggers**  
- **Data drift detection** with Evidently AI  

### ğŸ”§ CI/CD & Monitoring
- **Jenkins pipelines** for deployment and training
- **Microsoft Teams alert** integration  
- **Prefect dashboard** for workflow monitoring
- 
### ğŸš€ FastAPI Model Serving

**Minimal production API** that auto-serves the latest production model from MLflow registry 

## Quickstart

### 1. Clone the Repository
```bash
git clone https://github.com/norahosny66/predictive-maintenance-mlops.git
cd predictive-maintenance-mlops
```
### 2. â˜ï¸ Provision Infrastructure (Terraform)
```bash
cd terraform/
terraform init
terraform plan 
terraform apply
```
This will create:

EC2 instance with IAM Role

S3 bucket for model/data storage

Security groups with necessary ports open
### 3. Update Inventory for Ansible

```bash
cd ../ansible/
echo -e "[mlops]\n<your-ec2-public-ip>" > inventory.yml
```
### 4. âš™ï¸ Configure EC2 (Ansible)
```bash
ansible-playbook -i inventory.yml mlflow.yml
ansible-playbook -i inventory.yml prefect.yml
ansible-playbook -i inventory.yml jenkins.yml
```
### 5. ğŸ“¤ Upload Data to S3

### 6. Register & Run Prefect Flow
Build and apply Prefect deployment:
```bash
prefect deployment build pipeline.py:train_and_monitor -n "prod-flow"
prefect deployment apply train_and_monitor-deployment.yaml
prefect agent start
```
And do the same for monitoring pipeline
# MLflow tracking server

Access UIs:

Prefect â†’ http://<EC2_IP>:4200

MLflow â†’ http://<EC2_IP>:5050

Jenkins â†’ http://<EC2_IP>:8080


### Simulate Drift Detection & Retrain
```bash
docker exec -it prefect-prefect-agent-1  bash
prefect deployment apply prefect/monitor_pipeline-deployment.yaml
```
This will:

Detect drift (via Evidently AI)

Trigger retraining

## ğŸ“£ Teams Alert Configuration

1. **Create an incoming webhook** in your Microsoft Teams channel  
   - Go to your channel â†’ **Connectors** â†’ **Incoming Webhook** â†’ Generate URL

2. **Update `src/alert.py`** with your webhook URL:

   ```python
   WEBHOOK_URL = "https://..."
   
## FastAPI Model Serving
```bash
uvicorn api:app --reload  # Dev
gunicorn -w 4 -k uvicorn.workers.UvicornWorker api:app  # Prod
```
Access: http://localhost:8000/docs


## ğŸ™‹â€â™€ï¸ Maintainer

**Noura Hosny**  
SRE | Cloud & Automation Enthusiast  
ğŸ’¼ [LinkedIn Profile](https://www.linkedin.com/in/nourahosny81231/)

